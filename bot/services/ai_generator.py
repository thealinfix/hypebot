"""
AI content generation service using OpenAI
"""
import base64
import logging
from typing import Optional, List, Dict, Any
from io import BytesIO

from openai import AsyncOpenAI
from PIL import Image

from config import OPENAI_API_KEY, IMAGE_STYLES
from bot.utils.helpers import is_valid_url

logger = logging.getLogger(__name__)


class AIGenerator:
    """Service for AI content generation"""
    
    def __init__(self):
        self.client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        
        # Model fallback chain
        self.text_models = ["gpt-4o", "gpt-4-turbo", "gpt-4", "gpt-3.5-turbo"]
        self.vision_model = "gpt-4-vision-preview"
        self.image_model = "dall-e-3"
    
    async def generate_caption(self, title: str, context: str = "", 
                             category: str = "sneakers", 
                             is_thought: bool = False,
                             image_description: str = "") -> str:
        """Generate caption for post"""
        try:
            if is_thought:
                return await self._generate_thought_caption(title, image_description)
            else:
                return await self._generate_post_caption(title, context, category)
        except Exception as e:
            logger.error(f"Error generating caption: {e}")
            return self._get_fallback_caption(title, is_thought)
    
    async def _generate_post_caption(self, title: str, context: str, category: str) -> str:
        """Generate regular post caption"""
        system_prompt = """–¢—ã ‚Äî –∞–≤—Ç–æ—Ä Telegram-–∫–∞–Ω–∞–ª–∞ –ø—Ä–æ –∫—Ä–æ—Å—Å–æ–≤–∫–∏ –∏ —É–ª–∏—á–Ω—É—é –º–æ–¥—É. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–∏—Å–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–µ, —Ü–µ–ø–ª—è—é—â–∏–µ –∏ —Å—Ç–∏–ª—å–Ω—ã–µ –ø–æ—Å—Ç—ã –æ —Ä–µ–ª–∏–∑–∞—Ö, —Ç—Ä–µ–Ω–¥–∞—Ö –∏ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è—Ö. 

–ü–†–ê–í–ò–õ–ê –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø –≠–ú–û–î–ó–ò:
- –¢–û–õ–¨–ö–û –æ–¥–∏–Ω —ç–º–æ–¥–∑–∏ –≤ –Ω–∞—á–∞–ª–µ –ø–æ—Å—Ç–∞ (–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ/—Ç–µ–º–∞)
- –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –û–î–ò–ù —ç–º–æ–¥–∑–∏ –≤ –∫–æ–Ω—Ü–µ (–ø—Ä–∏–∑—ã–≤/–≤–æ–ø—Ä–æ—Å)
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—Å—Ç–∞
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –≤ –∫–∞–∂–¥–æ–º –∞–±–∑–∞—Ü–µ
- –ü–æ–¥—Ö–æ–¥—è—â–∏–µ —ç–º–æ–¥–∑–∏ –¥–ª—è –Ω–∞—á–∞–ª–∞: üî• ‚ö°Ô∏è üí´ üëü üö®
- –ü–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–ª—è –∫–æ–Ω—Ü–∞: üëÄ ü§î üí≠

–ü–∏—à–∏ –≤ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ-–º–æ–ª–æ–¥—ë–∂–Ω–æ–º —Ç–æ–Ω–µ: –±–µ–∑ –ø–∞—Ñ–æ—Å–∞, –±–µ–∑ –∫–∞–Ω—Ü–µ–ª—è—Ä–∏—Ç–∞, –±–µ–∑ –∂–∞—Ä–≥–æ–Ω–∞. –°—Ç–∏–ª—å ‚Äî –∂–∏–≤–æ–π, –ª—ë–≥–∫–∏–π, —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π.

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ—Å—Ç–∞:
1. –ù–∞—á–Ω–∏ —Å –û–î–ù–û–ì–û —ç–º–æ–¥–∑–∏ –∏ —Ü–µ–ø–ª—è—é—â–µ–π —Ñ—Ä–∞–∑—ã (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
2. –°—É—Ç—å —Ä–µ–ª–∏–∑–∞: –±—Ä–µ–Ω–¥, –º–æ–¥–µ–ª—å, –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ - –ë–ï–ó —ç–º–æ–¥–∑–∏
3. –î–µ—Ç–∞–ª–∏: –º–∞—Ç–µ—Ä–∏–∞–ª—ã, —Ü–≤–µ—Ç–∞, —á—Ç–æ –≤—ã–¥–µ–ª—è–µ—Ç - –ë–ï–ó —ç–º–æ–¥–∑–∏
4. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ: –º–Ω–µ–Ω–∏–µ –∏–ª–∏ –≤–æ–ø—Ä–æ—Å (–º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –û–î–ò–ù —ç–º–æ–¥–∑–∏ –≤ –∫–æ–Ω—Ü–µ)

–ò–∑–±–µ–≥–∞–π: –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π, —Ä–µ–∫–ª–∞–º–Ω—ã—Ö –∫–ª–∏—à–µ.
–ú–∞–∫—Å–∏–º—É–º 600 —Å–∏–º–≤–æ–ª–æ–≤."""
        
        user_prompt = f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}\n–î–µ—Ç–∞–ª–∏: {context[:500] if context else '–ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏'}"
        
        for model in self.text_models:
            try:
                response = await self.client.chat.completions.create(
                    model=model,
                    temperature=0.8,
                    max_tokens=300,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                )
                
                generated = response.choices[0].message.content.strip()
                logger.info(f"Caption generated successfully with {model}")
                
                # Add title if not present
                if title.lower() not in generated.lower():
                    generated = f"<b>{title}</b>\n\n{generated}"
                
                return generated
                
            except Exception as e:
                logger.error(f"Error with model {model}: {e}")
                continue
        
        # Fallback
        return self._get_fallback_caption(title, False)
    
    async def _generate_thought_caption(self, topic: str, image_description: str = "") -> str:
        """Generate thought/personal post caption"""
        system_prompt = """–¢—ã –≤–µ–¥–µ—à—å –ª–∏—á–Ω—ã–π –±–ª–æ–≥ –æ –∫—Ä–æ—Å—Å–æ–≤–∫–∞—Ö –∏ —É–ª–∏—á–Ω–æ–π –º–æ–¥–µ. –ü–∏—à–∏ –æ—Ç –ø–µ—Ä–≤–æ–≥–æ –ª–∏—Ü–∞, –∫–∞–∫ –±—É–¥—Ç–æ –¥–µ–ª–∏—à—å—Å—è —Å–≤–æ–∏–º–∏ –º—ã—Å–ª—è–º–∏ —Å –¥—Ä—É–∑—å—è–º–∏. –°—Ç–∏–ª—å –Ω–µ–ø—Ä–∏–Ω—É–∂–¥–µ–Ω–Ω—ã–π, —Å —ç–º–æ—Ü–∏—è–º–∏ –∏ –ª–∏—á–Ω—ã–º –æ—Ç–Ω–æ—à–µ–Ω–∏–µ–º. 

–ü–†–ê–í–ò–õ–ê –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø –≠–ú–û–î–ó–ò:
- –¢–û–õ–¨–ö–û –≤ –Ω–∞—á–∞–ª–µ –∞–±–∑–∞—Ü–∞ –∏–ª–∏ –≤—Å–µ–≥–æ –ø–æ—Å—Ç–∞
- –ù–ï –ë–û–õ–ï–ï –æ–¥–Ω–æ–≥–æ —ç–º–æ–¥–∑–∏ –Ω–∞ –∞–±–∑–∞—Ü
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –≤–Ω—É—Ç—Ä–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
- –ü–æ–¥—Ö–æ–¥—è—â–∏–µ —ç–º–æ–¥–∑–∏: üòç üî• üí≠ ü§î üòé ‚ú® üëü

–ú–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
- –õ–∏—á–Ω—ã–µ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è ("–º–Ω–µ –∫–∞–∂–µ—Ç—Å—è", "–ø–æ-–º–æ–µ–º—É", "—á–µ—Å—Ç–Ω–æ –≥–æ–≤–æ—Ä—è")
- –≠–º–æ—Ü–∏–∏ ("–æ–±–∞–ª–¥–µ–ª –∫–æ–≥–¥–∞ —É–≤–∏–¥–µ–ª", "–≤–ª—é–±–∏–ª—Å—è —Å –ø–µ—Ä–≤–æ–≥–æ –≤–∑–≥–ª—è–¥–∞")
- –°—Ä–∞–≤–Ω–µ–Ω–∏—è –∏–∑ –∂–∏–∑–Ω–∏
- –ù–µ–º–Ω–æ–≥–æ —é–º–æ—Ä–∞ –∏–ª–∏ –∏—Ä–æ–Ω–∏–∏ –≥–¥–µ —É–º–µ—Å—Ç–Ω–æ

–ú–∞–∫—Å–∏–º—É–º 500 —Å–∏–º–≤–æ–ª–æ–≤. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∑–∞–µ–∑–∂–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã."""
        
        if image_description:
            user_prompt = f"–ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç-—Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Ç–µ–º—ã.\n–¢–µ–º–∞: {topic}\n–û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_description}"
        else:
            user_prompt = f"–ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç-—Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–µ –æ: {topic}"
        
        for model in self.text_models:
            try:
                response = await self.client.chat.completions.create(
                    model=model,
                    temperature=0.9,
                    max_tokens=300,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                )
                
                generated = response.choices[0].message.content.strip()
                logger.info(f"Thought caption generated successfully with {model}")
                return generated
                
            except Exception as e:
                logger.error(f"Error with model {model}: {e}")
                continue
        
        # Fallback
        return self._get_fallback_caption(topic, True)
    
    def _get_fallback_caption(self, title: str, is_thought: bool) -> str:
        """Get fallback caption when AI fails"""
        if is_thought:
            return f"üí≠ {title}\n\n–ß—Ç–æ –¥—É–º–∞–µ—Ç–µ?"
        else:
            return f"<b>{title}</b>\n\nüî• –ù–æ–≤—ã–π —Ä–µ–ª–∏–∑. –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ —Å–∫–æ—Ä–æ!"
    
    async def generate_image(self, prompt: str, style: str = "photographic") -> Optional[str]:
        """Generate image using DALL-E 3"""
        try:
            logger.info(f"Generating image with prompt: {prompt[:50]}...")
            
            # Enhance prompt based on style
            enhanced_prompt = self._enhance_image_prompt(prompt, style)
            
            response = await self.client.images.generate(
                model=self.image_model,
                prompt=enhanced_prompt,
                size="1024x1024",
                quality="standard",
                n=1,
            )
            
            image_url = response.data[0].url
            logger.info("Image generated successfully")
            return image_url
            
        except Exception as e:
            logger.error(f"Error generating image: {e}")
            return None
    
    def _enhance_image_prompt(self, prompt: str, style: str) -> str:
        """Enhance image prompt based on style"""
        style_enhancements = {
            "photographic": "professional photography, studio lighting, high quality, sharp focus, 4k resolution",
            "editorial": "fashion magazine style, editorial photography, trendy aesthetic, professional",
            "artistic": "digital art, creative composition, vibrant colors, artistic interpretation",
            "creative": "imaginative, unique perspective, creative design, eye-catching",
        }
        
        enhancement = style_enhancements.get(style, "high quality, professional")
        return f"{prompt}, {enhancement}"
    
    async def analyze_image(self, image_data: bytes) -> str:
        """Analyze image using GPT-4 Vision"""
        try:
            # Convert to base64
            base64_image = base64.b64encode(image_data).decode('utf-8')
            
            response = await self.client.chat.completions.create(
                model=self.vision_model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "–û–ø–∏—à–∏ —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ —ç—Ç–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–µ. –û—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ —É–¥–µ–ª–∏ –¥–µ—Ç–∞–ª—è–º, —Ü–≤–µ—Ç–∞–º, —Å—Ç–∏–ª—é. –ï—Å–ª–∏ —ç—Ç–æ –∫—Ä–æ—Å—Å–æ–≤–∫–∏ –∏–ª–∏ –æ–¥–µ–∂–¥–∞ - –æ–ø–∏—à–∏ –º–æ–¥–µ–ª—å, –±—Ä–µ–Ω–¥, –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –¥–∏–∑–∞–π–Ω–∞."
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=300
            )
            
            description = response.choices[0].message.content.strip()
            logger.info("Image analyzed successfully")
            return description
            
        except Exception as e:
            logger.error(f"Error analyzing image: {e}")
            return ""
    
    async def generate_custom_image(self, post_title: str, style_key: str = "sneakers", 
                                  custom_prompt: Optional[str] = None) -> Optional[str]:
        """Generate custom image for post"""
        try:
            # Get style configuration
            style_config = IMAGE_STYLES.get(style_key, IMAGE_STYLES["sneakers"])
            
            # Build prompt
            if custom_prompt:
                prompt = style_config["prompt_template"].format(custom_prompt=custom_prompt)
            else:
                prompt = style_config["prompt_template"].format(title=post_title)
            
            # Generate image
            return await self.generate_image(prompt, style_config["style"])
            
        except Exception as e:
            logger.error(f"Error generating custom image: {e}")
            return None
    
    async def improve_text(self, text: str, instruction: str) -> str:
        """Improve or modify text based on instruction"""
        try:
            for model in self.text_models:
                try:
                    response = await self.client.chat.completions.create(
                        model=model,
                        temperature=0.7,
                        messages=[
                            {
                                "role": "system",
                                "content": "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ä–µ–¥–∞–∫—Ç–æ—Ä —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π."
                            },
                            {
                                "role": "user",
                                "content": f"–£–ª—É—á—à–∏ —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç —Å–æ–≥–ª–∞—Å–Ω–æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏.\n\n–¢–µ–∫—Å—Ç: {text}\n\n–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: {instruction}"
                            }
                        ],
                    )
                    
                    return response.choices[0].message.content.strip()
                    
                except Exception as e:
                    logger.error(f"Error with model {model}: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"Error improving text: {e}")
        
        return text  # Return original if failed
    
    async def generate_hashtags(self, text: str, category: str = "sneakers") -> str:
        """Generate relevant hashtags for text"""
        try:
            prompt = f"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π 5-7 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ö—ç—à—Ç–µ–≥–æ–≤ –¥–ª—è —ç—Ç–æ–≥–æ –ø–æ—Å—Ç–∞ –æ {'–∫—Ä–æ—Å—Å–æ–≤–∫–∞—Ö' if category == 'sneakers' else '–º–æ–¥–µ'}. –¢–µ–∫—Å—Ç: {text[:200]}"
            
            for model in self.text_models:
                try:
                    response = await self.client.chat.completions.create(
                        model=model,
                        temperature=0.5,
                        max_tokens=100,
                        messages=[
                            {
                                "role": "system",
                                "content": "–ì–µ–Ω–µ—Ä–∏—Ä—É–π —Ç–æ–ª—å–∫–æ —Ö—ç—à—Ç–µ–≥–∏, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª–∞–º–∏. –ò—Å–ø–æ–ª—å–∑—É–π –∫–∞–∫ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ, —Ç–∞–∫ –∏ —Ä—É—Å—Å–∫–∏–µ —Ö—ç—à—Ç–µ–≥–∏."
                            },
                            {
                                "role": "user",
                                "content": prompt
                            }
                        ],
                    )
                    
                    hashtags = response.choices[0].message.content.strip()
                    # Ensure hashtags start with #
                    hashtags = ' '.join(f"#{tag.lstrip('#')}" for tag in hashtags.split())
                    return hashtags
                    
                except Exception as e:
                    logger.error(f"Error with model {model}: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"Error generating hashtags: {e}")
        
        # Fallback
        if category == "sneakers":
            return "#sneakers #–∫—Ä–æ—Å—Å–æ–≤–∫–∏ #streetwear #–æ–±—É–≤—å"
        else:
            return "#fashion #–º–æ–¥–∞ #streetwear #style"
    
    async def check_content_appropriateness(self, text: str) -> bool:
        """Check if content is appropriate for posting"""
        try:
            response = await self.client.moderations.create(input=text)
            
            results = response.results[0]
            
            # Check if any category is flagged
            flagged = results.flagged
            
            if flagged:
                logger.warning(f"Content flagged by moderation: {results.categories}")
            
            return not flagged
            
        except Exception as e:
            logger.error(f"Error checking content appropriateness: {e}")
            return True  # Allow by default if check fails


# Singleton instance
ai_generator = AIGenerator()
